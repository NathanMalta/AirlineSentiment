{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanmalta/miniconda3/envs/twitter/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import facebook_scraper as fs\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, grab the last 400 posts without comments\n",
    "\n",
    "This can be done quickly, and we can use the post urls to restart scraping where we left off if there is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanmalta/miniconda3/envs/twitter/lib/python3.11/site-packages/facebook_scraper/facebook_scraper.py:912: UserWarning: Facebook says 'Unsupported Browser'\n",
      "  warnings.warn(f\"Facebook says 'Unsupported Browser'\")\n",
      "  0%|          | 0/400 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m posts \u001b[39m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(NUM_POSTS)):\n\u001b[0;32m---> 22\u001b[0m     new \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(gen)\n\u001b[1;32m     23\u001b[0m     posts\u001b[39m.\u001b[39mappend(new)\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/facebook_scraper/facebook_scraper.py:1114\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m counter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mcount(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m page_limit \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mrange\u001b[39m(page_limit)\n\u001b[1;32m   1113\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mStarting to iterate pages\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1114\u001b[0m \u001b[39mfor\u001b[39;00m i, page \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(counter, iter_pages_fn()):\n\u001b[1;32m   1115\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mExtracting posts from page \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, i)\n\u001b[1;32m   1116\u001b[0m     \u001b[39mfor\u001b[39;00m post_element \u001b[39min\u001b[39;00m page:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/facebook_scraper/page_iterators.py:87\u001b[0m, in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRequesting page from: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, next_url)\n\u001b[0;32m---> 87\u001b[0m     response \u001b[39m=\u001b[39m request_fn(next_url)\n\u001b[1;32m     88\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/facebook_scraper/facebook_scraper.py:871\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mpost(url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 871\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mget(url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequests_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    872\u001b[0m DEBUG \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/requests/sessions.py:542\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[1;32m    536\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/requests/sessions.py:687\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 687\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    689\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/requests/models.py:838\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 838\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    840\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/requests/models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    759\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    761\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m    762\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/urllib3/response.py:831\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_chunk(amt)\n\u001b[1;32m    832\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(\n\u001b[1;32m    833\u001b[0m     chunk, decode_content\u001b[39m=\u001b[39mdecode_content, flush_decoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    834\u001b[0m )\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/site-packages/urllib3/response.py:784\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    782\u001b[0m     returned_chunk \u001b[39m=\u001b[39m value\n\u001b[1;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# amt > self.chunk_left\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m     returned_chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49m_safe_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_left)\n\u001b[1;32m    785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39m_safe_read(\u001b[39m2\u001b[39m)  \u001b[39m# Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/http/client.py:631\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[1;32m    633\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/twitter/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of comments to download -- set this to True to download all comments\n",
    "MAX_COMMENTS = 100\n",
    "NUM_POSTS = 400\n",
    "\n",
    "airline = 'SpiritAirlines' #or 'SouthwestAir' or 'AmericanAirlines' or 'Delta'\n",
    "\n",
    "#enter a facebook account email and password (use a fake account as there's a chance it could get banned)\n",
    "account_email = ''\n",
    "account_password = ''\n",
    "\n",
    "# get the post (this gives a generator)\n",
    "gen = fs.get_posts(\n",
    "    account=airline, \n",
    "    pages=50,\n",
    "    options={\"comments\": MAX_COMMENTS, \"progress\": True, 'allow_extra_requests': False, 'posts_per_page': 100}, \n",
    "    credentials=(account_email, account_password)\n",
    ")\n",
    "\n",
    "# take 1st element of the generator which is the post we requested\n",
    "posts = []\n",
    "for _ in tqdm(range(NUM_POSTS)):\n",
    "    new = next(gen)\n",
    "    posts.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save posts\n",
    "with open('posts_no_com/spirit.pkl', 'wb') as f:\n",
    "    pickle.dump(posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load posts\n",
    "with open('posts_no_com/spirit.pkl', 'rb') as f:\n",
    "    posts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, start scraping the posts for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COMMENTS = 50\n",
    "NUM_POSTS = 400\n",
    "\n",
    "posts_with_comments = []\n",
    "\n",
    "if os.path.exists('posts_with_com/spirit/spirit.pkl'):\n",
    "    with open('posts_with_com/spirit/spirit.pkl', 'rb') as f:\n",
    "        posts_with_comments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start (or restart) downloading comments\n",
    "while len(posts_with_comments) < NUM_POSTS:\n",
    "    print(len(posts_with_comments))\n",
    "    post = posts[len(posts_with_comments)]\n",
    "    url = post['post_url']\n",
    "    gen = fs.get_posts(\n",
    "        post_urls=[url],\n",
    "        options={\"comments\": MAX_COMMENTS, \"progress\": True, 'allow_extra_requests': False, 'posts_per_page': 100}, \n",
    "        credentials=(account_email, account_password)\n",
    "        # cookies='cookies.json'\n",
    "    )\n",
    "    posts_with_comments.append(next(gen))\n",
    "    sleep_time = random.randint(1, 5)\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save downloaded posts + comments to a file\n",
    "with open('scraped_data/spirit.pkl', 'wb') as f:\n",
    "    pickle.dump(posts_with_comments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view a post and its comments\n",
    "print('num posts', len(posts_with_comments))\n",
    "post_num = 399\n",
    "print(posts_with_comments[post_num]['text'])\n",
    "print(f'num comments: {len(posts_with_comments[post_num][\"comments_full\"])}')\n",
    "for comment in posts_with_comments[post_num]['comments_full']:\n",
    "    print(comment['comment_text'])\n",
    "\n",
    "print(posts_with_comments[post_num]['time'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
